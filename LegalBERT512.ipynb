{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LegalBERT Model Implementation for Classification (Without Strides max length 512 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spyman/Documents/Deep Learning/LAW-AI classification/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spyman/Documents/Deep Learning/LAW-AI classification/myenv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Input.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['Text'].values, df['Label'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      1\n",
       "2      2\n",
       "3      1\n",
       "4      2\n",
       "      ..\n",
       "502    0\n",
       "503    2\n",
       "504    1\n",
       "505    1\n",
       "506    1\n",
       "Name: Label, Length: 507, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalCaseDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = LegalCaseDataset(train_encodings, train_labels)\n",
    "val_dataset = LegalCaseDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/spyman/Documents/Deep Learning/LAW-AI classification/myenv/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('nlpaueb/legal-bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 10/255 [01:51<44:04, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4504, 'grad_norm': 9.02530574798584, 'learning_rate': 4.803921568627452e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 20/255 [03:42<43:00, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2192, 'grad_norm': 6.287754535675049, 'learning_rate': 4.607843137254902e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 30/255 [05:29<40:36, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9154, 'grad_norm': 8.350238800048828, 'learning_rate': 4.411764705882353e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 40/255 [07:13<37:05, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6335, 'grad_norm': 11.303633689880371, 'learning_rate': 4.215686274509804e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñâ        | 50/255 [08:57<35:17, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5739, 'grad_norm': 7.7934346199035645, 'learning_rate': 4.0196078431372555e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 20%|‚ñà‚ñà        | 51/255 [09:42<31:28,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43772608041763306, 'eval_runtime': 38.8758, 'eval_samples_per_second': 2.624, 'eval_steps_per_second': 0.334, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñé       | 60/255 [11:24<37:31, 11.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3641, 'grad_norm': 11.585156440734863, 'learning_rate': 3.8235294117647055e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 70/255 [13:13<33:58, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3788, 'grad_norm': 7.605222702026367, 'learning_rate': 3.627450980392157e-05, 'epoch': 1.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 80/255 [15:00<30:45, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3593, 'grad_norm': 7.202467441558838, 'learning_rate': 3.431372549019608e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 90/255 [16:51<31:00, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4083, 'grad_norm': 9.72778034210205, 'learning_rate': 3.235294117647059e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 100/255 [18:44<29:00, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3098, 'grad_norm': 11.955645561218262, 'learning_rate': 3.0392156862745097e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 102/255 [19:40<25:17,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40606817603111267, 'eval_runtime': 38.6433, 'eval_samples_per_second': 2.64, 'eval_steps_per_second': 0.336, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 110/255 [21:10<28:28, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1571, 'grad_norm': 1.3881723880767822, 'learning_rate': 2.8431372549019608e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 120/255 [22:57<23:40, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2281, 'grad_norm': 1.36797034740448, 'learning_rate': 2.647058823529412e-05, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 130/255 [24:43<22:03, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2235, 'grad_norm': 5.24509859085083, 'learning_rate': 2.4509803921568626e-05, 'epoch': 2.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 140/255 [26:32<21:18, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1696, 'grad_norm': 6.003516674041748, 'learning_rate': 2.2549019607843138e-05, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 150/255 [28:22<19:32, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1775, 'grad_norm': 9.213173866271973, 'learning_rate': 2.058823529411765e-05, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 153/255 [29:30<16:38,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3654736578464508, 'eval_runtime': 38.7049, 'eval_samples_per_second': 2.635, 'eval_steps_per_second': 0.336, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 160/255 [30:49<19:45, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0678, 'grad_norm': 0.15297530591487885, 'learning_rate': 1.862745098039216e-05, 'epoch': 3.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 170/255 [32:38<15:42, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1882, 'grad_norm': 9.639248847961426, 'learning_rate': 1.6666666666666667e-05, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 180/255 [34:29<13:43, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0319, 'grad_norm': 0.13586165010929108, 'learning_rate': 1.4705882352941177e-05, 'epoch': 3.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 190/255 [36:20<11:58, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0904, 'grad_norm': 9.222332000732422, 'learning_rate': 1.2745098039215686e-05, 'epoch': 3.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 200/255 [38:19<10:45, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0798, 'grad_norm': 8.501423835754395, 'learning_rate': 1.0784313725490197e-05, 'epoch': 3.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 204/255 [39:43<08:25,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46169158816337585, 'eval_runtime': 44.1705, 'eval_samples_per_second': 2.309, 'eval_steps_per_second': 0.294, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 210/255 [40:54<10:11, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.049, 'grad_norm': 0.2023674100637436, 'learning_rate': 8.823529411764707e-06, 'epoch': 4.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 220/255 [42:49<06:34, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0209, 'grad_norm': 0.07120305299758911, 'learning_rate': 6.862745098039216e-06, 'epoch': 4.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 230/255 [44:50<05:08, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0569, 'grad_norm': 0.07479564100503922, 'learning_rate': 4.901960784313726e-06, 'epoch': 4.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 240/255 [46:51<02:57, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0659, 'grad_norm': 0.09021677821874619, 'learning_rate': 2.9411764705882355e-06, 'epoch': 4.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 250/255 [48:49<00:59, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1982, 'grad_norm': 0.06691382825374603, 'learning_rate': 9.80392156862745e-07, 'epoch': 4.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 255/255 [50:26<00:00, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47604843974113464, 'eval_runtime': 41.7284, 'eval_samples_per_second': 2.444, 'eval_steps_per_second': 0.312, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 255/255 [50:28<00:00, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3028.6235, 'train_samples_per_second': 0.669, 'train_steps_per_second': 0.084, 'train_loss': 0.3302167962725256, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=255, training_loss=0.3302167962725256, metrics={'train_runtime': 3028.6235, 'train_samples_per_second': 0.669, 'train_steps_per_second': 0.084, 'total_flos': 532809454694400.0, 'train_loss': 0.3302167962725256, 'epoch': 5.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Case Type: Civil Case\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('./fine-tuned-Legalbert512')\n",
    "tokenizer.save_pretrained('./fine-tuned-Legalbert512')\n",
    "def classify_case(text):\n",
    "    encoding = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**encoding)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return label_encoder.inverse_transform([predicted_class_id])[0]\n",
    "\n",
    "example_text = '''M. JAGANNADHA RAO. J. This case concerns the proceedings arising out of an order of this Court dated 4.5.2000 proposing to re-open the quantum of punishments imposed in departmental inquiries on certain officers of the Delhi Development Authority (hereinafter called the DDA) who were connected with the land of the DDA allotted to M/s Skipper Construction Co. It was proposed to consider imposition of higher degree of punishments in view of the role of these officers in the said matter. After directions were given by this Court that disciplinary action be taken and punishments were imposed, this Court had no occasion to examine whether the right punishments were awarded to the officers in accordance with well known principles of law or whether the punishments required any upward revision.\n",
    "The facts of the case limited to the present order are as follows :\n",
    "By an order dated 29.11.94, this Court requested Justice O. Chinnappa Reddy (former Judge of this Court), to investigate into the conduct of the officials of the DDA including its ex-officio chairman at the relevant time, in handing over the possession of the suit land in M/s. Skipper Construction Pvt. Ltd. before receiving the auction amount in full and also in \"conniving\" at the construction thereon as well as at the advertisements given by it for bookings in the building in question. The learned Judge was also requested to \"look into the legality and propriety of the order dated 4.10.98 passed by the then ex-officio Chairman of the DDA and the directions given by the Central Government under Section 41 of the Delhi Development Act.\"\n",
    "Chairman to whom the file had been put up again on 2.6.1982 to confirm the telephonic instructions alleged to have been received from Baidwan nor was the matter brought to the notice of the Lt. Governor immediately as required under the Rules. The Union Public Service Commission had further noted that the Vice-Chairman, as a matter of fact, had stated before Justice Chinnappa Reddy Commission that he did not recollect exactly the conversation he had with Sri Baidwan on 28.5.1982.'''\n",
    "prediction = classify_case(example_text)\n",
    "print(f\"Predicted Case Type: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import joblib\n",
    "tokenizer = BertTokenizer.from_pretrained('./fine-tuned-Legalbert512')\n",
    "model = BertForSequenceClassification.from_pretrained('./fine-tuned-Legalbert512')\n",
    "label_encoder = joblib.load('label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Case Type: Criminal Case\n"
     ]
    }
   ],
   "source": [
    "def classify_case(text):\n",
    "    encoding = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**encoding)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return label_encoder.inverse_transform([predicted_class_id])[0]\n",
    "\n",
    "example_text = '''Facts: On the night of 5th September 2019, the accused, Dhananjay Singh, allegedly murdered his neighbor, Mr. Ravi Kumar, following a heated argument over a property dispute in Mumbai, Maharashtra. Witnesses reported hearing loud voices coming from the victim's house, followed by a gunshot. The police arrested Dhananjay Singh at the scene, where he was found holding a firearm.\n",
    "\n",
    "Prosecution's Argument: The prosecution argued that Dhananjay Singh had a motive for murder due to the ongoing property dispute. They presented eyewitness testimonies that placed him at the scene and forensic evidence linking the firearm in his possession to the bullet found in the victim's body. The prosecution sought to prove that the act was premeditated and planned, making it a case of first-degree murder under Section 302 of the Indian Penal Code (IPC).\n",
    "\n",
    "Defense's Argument: The defense contended that Dhananjay Singh acted in self-defense, claiming that the victim attacked him first with a knife, and in the struggle, the gun accidentally discharged. The defense argued that there was no intention to kill, and therefore, the charges should be reduced to culpable homicide not amounting to murder under Section 304 of the IPC.\n",
    "\n",
    "Judgment: The court, after considering the evidence and witness testimonies, found Dhananjay Singh guilty of murder under Section 302 of the IPC. The court held that the defense's argument of self-defense was not supported by the evidence, and the killing was deliberate and intentional. The accused was sentenced to life imprisonment.'''\n",
    "prediction = classify_case(example_text)\n",
    "print(f\"Predicted Case Type: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
